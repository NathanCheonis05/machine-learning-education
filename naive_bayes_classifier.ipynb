{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifer \n",
    "\n",
    "I am making a naive bayes classifier with the `scikit-learn` library and I will be using the `pandas` and `plotly` libraries. Naive Bayes uses Byaes Theorem which is as follows:\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Bayes Theorem calculates the probability of a class given a set of features, assuming that the features are independent. Despite this \"naive\" assumption of feature independence, it performs in many practical applications, especially high-dimensional data. The algorithm computes the posterior probability of each class and assigns the class label with the highest posterior probability. It is also important to mention that the Naive Bayes Algorithm that all dependent variables are independent which is again the \"naive\" assumption that it makes. It is commonly used in text classification, such as spam detection and sentiment analysis. Naive Bayes is efficent, easy to implement and works well with small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
